Consider the function $e^{-t}$ on the interval $[0,\infty)$. Let
$\pi_{k,k}\subset \mathbb{R}(t)$ be the set of rational functions $r_{k,k}(t)
= p_k(t)/q_k(t)$, where $p_k(t), q_k(t)\in \mathbb{R}[t]$ are polynomials of
degree at most $k$.

Chebyshev Rational Approximation Method (CRAM)~\cite{ationneeded} approximation of degree $k$
for $e^{-t}$ is the unique rational function $\hat{r}_{k,k}(t)$ such that
\begin{equation}
  \sup_{t\in[0, \infty)}|\hat{r}_{k, k}(t) - e^{-t}|
\end{equation}
is minimized. That is,
\begin{equation}
  \epsilon_{k,k} = \sup_{t\in[0, \infty)}|\hat{r}_{k, k}(t) - e^{-t}| = \inf_{r_{k,k}\in\pi_{k,k}}\left\{\sup_{t\in[0, \infty)}|r_{k, k}(t) - e^{-t}|\right\}.
\end{equation}
$\epsilon_{k,k}$ is the absolute error of the approximation. It has been shown
that $\epsilon_{k,k} = O(H^{-k})$, where $H=9.289\ldots$~\cite{ationneeded}.

Transmutagen implements the Remez algorithm to compute the CRAM approximation.
All computations are performed using SymPy~\cite{10.7717/peerj-cs.103}
symbolic expressions with arbitrary precision floating point numbers, which
are backed by the mpmath library~\cite{ationneeded}.

The interval $[0, \infty)$ is first translated to $[-1, 1)$ via the
transformation $t\mapsto c\frac{t+1}{t-1}$. \todo{cite Carpenter paper here.}
\todo{discuss this {\it after} discussing finding the roots.} The constant $c$
is chosen so that the minimax roots of the approximation are distributed
sufficiently evenly across the interval $[-1, 1)$. We found that the value
$c=0.6k$ works well.

The expressions
\begin{equation}
  r := \frac{p_kt^k + \cdots + p_1t + p_0}{q_kt^k + \cdots +
    q_1t + 1},
\end{equation}
\begin{equation}
  D := e^{c\frac{t+1}{t-1}} - r,
\end{equation}
and
\begin{equation}
  E := D + (-1)^i\epsilon
\end{equation}
are represented symbolically as SymPy expressions. This expression $E$ is
then evaluated in $t$ at $2(k + 1)$ points in the interval $(-1, 1)$ for
$i=0\ldots 2k+1$. For the first iteration of the algorithm, any set of initial
points can be used. We used the Chebyshev nodes~\cite{ationneeded}, that is,
the roots of $T_{2(k +1)}(x)$, which always lie in the interval $(-1, 1)$
($T_n(x)$ is defined as $T_n(\cos(x)) = \cos(nx)$). We found that convergence
can take more than twice as many steps when random initial points are used
instead of the Chebyshev nodes. \todo{verify this.} This results in a
nonlinear system of $2(k+1)$ equations in $2(k+1)$ variables
($p_0,\ldots,p_k,q_1,\ldots,q_k,\epsilon$). These are solved using the
\texttt{sympy.nsolve} function, which internally uses \texttt{mpmath.findroot}
to apply Newton's method~\cite{ationneeded} with a symbolically computed
Jacobian.

The solution to this system is then substituted into $D$. The critical points
of this function on the interval $[-1, 1)$ are then found. This is done by
taking the symbolic derivative of $D$, splitting the interval into
subintervals, and performing bisection using \texttt{nsolve} on each
subinterval. Let $\{z_i\}$ be the set of critical points on $[-1, 1)$,
including the end-points $D|_{t=-1}$ and $\lim_{t\to 1} D=-r|_{t=1}$. There
are $2(k+1)$ points $\{z_i\}$. The points $\{z_i\}$ are used as the set of
initial points for the next iteration, and the algorithm iterates as such
until convergence is reached.

By the theory~\cite{ationneeded}, the approximation $\hat{r}_{k, k}$ is known
to be minimal for a given order $k$ when the critical points of
$\hat{r}_{k, k}(t) - e^{-t}$ oscillate in sign and have equal absolute value.
For the iterates of the algorithm, the points $z_i$ are these critical points
of the current approximation, so convergence is detected by looking at
$\varepsilon_N = \max{|z_i|} - \min{|z_i|}$, for the $N$th iteration of the
algorithm. Convergence occurs roughly when $\varepsilon_N$ is near $10^{-d}$,
where $d$ decimal digits are used in the calculations. However, the true
minimal value of $\varepsilon_N$ depends on both $k$ and $d$. We found a
robust heuristic to be to iterate until $\log_{10}{(\varepsilon_N)}$ is near
$-d$, then stop iterating when the values of $\varepsilon_N$ become
log-convex. See Figure~\ref{fig:convergence-14-1000} for an example of the
convergence of $\varepsilon_N$ for degree 14, 1000 digits of precision.

\begin{figure}[!ht]
\centering
\includegraphics[width=0.9\textwidth]{convergence-14-1000.eps}
\caption{Convergence of the Remez algorithm for degree 14, 1000 digits of
  precision.}
\label{fig:convergence-14-1000}
\end{figure}

Once the algorithm converges, the rational function is translated back to the
interval $[0, \infty)$ via the inverse transformation $t\mapsto \frac{t - c}{t
  + c}$. This must be done with care to avoid losing precision. For a
polynomial $f$ and rational function $p/q$, the SymPy
method \texttt{Poly.transform} efficiently computes
$q^nf\left(p/q\right)$ without losing precision. The resulting
rational function is normalized so that the constant term in the denominator
is 1, which matches the form used in the literature.~\cite{ationneeded}

The Remez algorithm is outlined in Figure~\ref{remez-pseudocode} as pseudocode.

% TODO: Figure out how to use \begin{algorithm} instead of \begin{figure}
\begin{figure}
  \caption{Remez algorithm for CRAM approximation of $e^{-t}$ on $[0, \infty)$
  of degree $n$.}
  \label{remez-pseudocode}
  \begin{algorithmic}
    \STATE \todo{better comment style}
    \STATE $k$ is the order of the approximation
    \STATE \COMMENT{translate $[0, \infty)$ to $[-1, 1)$}
    \STATE $t, p_0, \ldots, p_k, q_1, \ldots, q_k, \epsilon$ are symbolic variables
    \STATE $r \leftarrow \frac{p_kt^k + \cdots + p_1t + p_0}{q_kt^k + \cdots +
      q_1t + 1}$
    \STATE $c \leftarrow 0.6k$
    \STATE $D \leftarrow e^{c\frac{t+1}{t-1}} - r$
    \STATE $E_i \leftarrow D + (-1)^i\epsilon$

    \STATE $\{z_i\} \leftarrow$ Chebyshev nodes of order $2(k+1)$
    \STATE $N \leftarrow 1$
    \REPEAT
      \STATE $E_i \leftarrow E|_{z_i}$
      \STATE $sol \leftarrow$ Solve $\{E_i\}$ for $(p_0,\ldots,p_k,q_1,\ldots,q_k,\epsilon)$
      \STATE $z_0 \leftarrow D|_{t=-1}$
      \STATE $z_i \leftarrow$ $i^\mathrm{th}$ critical point of $D|_{sol}$ on
      $(-1, 1)$ \COMMENT{$i=1\ldots 2n$}
      \STATE $z_{2(k + 1)} \leftarrow -r|_{t=1}$ \COMMENT{$\lim_{t\to 1} D$}
      \STATE $\varepsilon_N \leftarrow \max{|z_i|} - \min{|z_i|}$
      \STATE $N \leftarrow N + 1$
    \UNTIL {convergence condition: $\log_{10}(\varepsilon_N) \approx -d$ \AND
      $\varepsilon_N$ is log-convex}
    \STATE $r_{final} = r|_{t=\frac{t - c}{t + c}}$ \COMMENT{translate $[-1, 1)$ back to $[0, \infty)$ and normalize $q_0=1$}
  \end{algorithmic}
\end{figure}
